{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter7.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python385jvsc74a57bd049d76db75e1e28746d71c3f6b25c62af887e3a226b459dd4a66c59b073abe6db",
      "display_name": "Python 3.8.5 64-bit ('base': conda)"
    },
    "metadata": {
      "interpreter": {
        "hash": "bc5325771484cd741460cbbcf20a153b1ef45b389ce85e60a186ce6bd8aea41f"
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hank199599/deep_learning_keras_log/blob/main/Chapter7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWlaJkQvPsuX"
      },
      "source": [
        "# 超越序列式模型\n",
        "\n",
        "* 單輸入模型\n",
        "* 多輸入模型\n",
        "* 殘差連接層(residual connections)層：透過特徵圖(張量)相加，將先前的資訊重新注入下游資料流"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7itMEtqQFLK"
      },
      "source": [
        "## [函數式API](https://keras.io/guides/functional_api/)\n",
        "\n",
        "使用Input()方法來檢立一個張量，並將張量直接傳入層(layer)或模型(model)之中，  \n",
        "取得處理後的結果張量。\n",
        "```python\n",
        "from keras import Input,layers\n",
        "\n",
        "input_tensor = Input(shape=(32,)) #建立一個輸入張量\n",
        "print(input_tensor.shape)\n",
        "\n",
        "dense = layers.Dense(16,activation='relu') #建立一個Dense層，並將其想像成一個函數\n",
        "output_tensor = dense(input_tensor) # 將張量輸入層函數，他會回傳經處理後的結果張亮\n",
        "print(output_tensor.shape)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUAIZlg0SRhq"
      },
      "source": [
        "### 序列式 與 函數式 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOQISgnqVhgt"
      },
      "source": [
        "序列式(Sequential)建立模型  \n",
        "![pic 7-1](https://raw.githubusercontent.com/hank199599/deep_learning_keras_log/main/pictures/7-1.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQwm5uoASXRv",
        "outputId": "c9bf25d3-1e51-45e8-bccc-9f339be2ac89"
      },
      "source": [
        "from keras.models import Sequential,Model\n",
        "from keras import layers,Input\n",
        "\n",
        "model=Sequential()\n",
        "model.add(layers.Dense(32,activation='relu',input_shape=(64,)))\n",
        "model.add(layers.Dense(32,activation='relu'))\n",
        "model.add(layers.Dense(32,activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                1056      \n",
            "=================================================================\n",
            "Total params: 4,192\n",
            "Trainable params: 4,192\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIYaPQBPV9BF"
      },
      "source": [
        "#### 函數式(API)建立模型\n",
        "透過建立**Model物件**，\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHYkLSg1Vf5l",
        "outputId": "6f9a4152-9c7c-420b-b21f-c034d3c757bf"
      },
      "source": [
        "input_tensor = Input(shape=(64,)) # 建立一個初始張量\n",
        "\n",
        "x = layers.Dense(32,activation='relu')(input_tensor)\n",
        "\n",
        "y = layers.Dense(32,activation='relu')(x)\n",
        "\n",
        "output_tensor = layers.Dense(10,activation='softmax')(y)\n",
        "\n",
        "model = Model(input_tensor,output_tensor)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 64)]              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 3,466\n",
            "Trainable params: 3,466\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rwg5AP8dbsu"
      },
      "source": [
        "如果用完全不相干的輸入和輸出張量去建構模型。  \n",
        "因為Keras找不到相關資訊，導致執行時會生錯誤。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "rr8SHU7adqko",
        "outputId": "8c94d955-66ea-47b0-bebd-a8778122ed1f"
      },
      "source": [
        "unrelated_input = Input(shape=(32,))\n",
        "bad_model = model = Model(unrelated_input,output_tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-be4c35b96e38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0munrelated_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbad_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munrelated_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFunctional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     nodes, nodes_by_depth, layers, _ = _map_graph_network(\n\u001b[0;32m--> 204\u001b[0;31m         self.inputs, self.outputs)\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m    988\u001b[0m                              \u001b[0;34m'The following previous layers '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m                              \u001b[0;34m'were accessed without issue: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m                              str(layers_with_complete_input))\n\u001b[0m\u001b[1;32m    991\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0mcomputable_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\") at layer \"dense_3\". The following previous layers were accessed without issue: []"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A4ZYHw6d8qO"
      },
      "source": [
        "在編譯、訓練或驗證此Model物件時，API的功能與序列式模型相同"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "451uIm70d8yn",
        "outputId": "968c8768-6839-42a2-80ee-7a68451c942c"
      },
      "source": [
        "model.compile(optimizer='rmsprop',loss='categorical_crossentropy')\n",
        "import numpy as np\n",
        "\n",
        "x_train = np.random.random((1000,64))\n",
        "y_train = np.random.random((1000,10))\n",
        "\n",
        "# 將訓練輸入模型進行訓練\n",
        "model.fit(x_train,y_train,epochs=10,batch_size=128)\n",
        "score = model.evaluate(x_train,y_train)\n",
        "print(score) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 1s 2ms/step - loss: 12.2086\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 12.1521\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 12.6796\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 13.6005\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 14.9342\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 16.7674\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 18.6711\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 21.3209\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 24.0460\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 27.5270\n",
            "32/32 [==============================] - 0s 931us/step - loss: 30.1749\n",
            "30.174882888793945\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofuO1uReenDJ"
      },
      "source": [
        "## 多輸入模型\n",
        "\n",
        "*[範例]*：典型的問答模型  \n",
        "必須針對問題產生出答案，可透過softmax分類器針對某些事件先定義好詞彙並輸出答案  \n",
        "![pic 7-3](https://raw.githubusercontent.com/hank199599/deep_learning_keras_log/main/pictures/7-3.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDZpMCc5et4k",
        "outputId": "d407d4fe-3b0c-4bc5-a7b0-bce0e2c35431"
      },
      "source": [
        "from keras import Model \n",
        "from keras import layers\n",
        "from keras import Input\n",
        "\n",
        "text_vocabulary_size = 10000\n",
        "question_vocabulary_size = 10000\n",
        "answer_vocabulary_size = 500\n",
        "\n",
        "text_input = Input(shape=(None,),dtype='int32',name='text')\n",
        "embedded_text = layers.Embedding(text_vocabulary_size,64)(text_input)\n",
        "print(embedded_text.shape)\n",
        "encoded_text = layers.LSTM(32)(embedded_text)\n",
        "print(encoded_text.shape)\n",
        "\n",
        "question_input = Input(shape=(None,),dtype='int32',name='question')\n",
        "embedded_question = layers.Embedding(question_vocabulary_size,32)(question_input)\n",
        "print(embedded_question.shape)\n",
        "encoded_question = layers.LSTM(16)(embedded_question)\n",
        "print(encoded_question.shape)\n",
        "\n",
        "concatenated = layers.concatenate([encoded_question,encoded_text],axis=1)\n",
        "print(concatenated.shape)\n",
        "\n",
        "answer = layers.Dense(answer_vocabulary_size,activation='softmax')(concatenated)\n",
        "print(answer.shape)\n",
        "\n",
        "model = Model([text_input,question_input],answer)\n",
        "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, None, 64)\n",
            "(None, 32)\n",
            "(None, None, 32)\n",
            "(None, 16)\n",
            "(None, 48)\n",
            "(None, 500)\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "question (InputLayer)           [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "text (InputLayer)               [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 32)     320000      question[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 64)     640000      text[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 16)           3136        embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 32)           12416       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 48)           0           lstm_1[0][0]                     \n",
            "                                                                 lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 500)          24500       concatenate[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 1,000,052\n",
            "Trainable params: 1,000,052\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9l-spDSntiE"
      },
      "source": [
        "### 訓練雙輸入模型的方法\n",
        "1. 為模型準備Numpy陣列\n",
        "2. 選擇下列兩種方式進行訓練 \n",
        "①將 Numpy 陣列資料組成串列(list)做為輸入進行訓練。  \n",
        "②建立一個字典(dict), 將輸入透過鍵(輸入名稱),對應到值(Numpy陣列資料)。當然,此方法只有在為輸入命名時才可用,例如上面程式中的第7行\n",
        "```python\n",
        "Input(., name = 'text,\n",
        "```\n",
        "我們就可以建立 dict:\n",
        "```python\n",
        "{'text': Numpy 資料}  \n",
        "```\n",
        "做為此輸入張量對應的 Numpy 資料。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lDzxjippD6O",
        "outputId": "4d167007-138d-461a-f0c3-0a9ae2d84582"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "num_samples = 1000\n",
        "max_length = 100\n",
        "\n",
        "# 產生虛擬text資料：1000筆，每筆100個字(數字)\n",
        "text = np.random.randint(1,text_vocabulary_size,size = (num_samples,max_length))\n",
        "print(text.shape)\n",
        "\n",
        "# 產生虛擬question資料：1000筆，每筆100個字(數字)\n",
        "question = np.random.randint(1,question_vocabulary_size,size = (num_samples,max_length))\n",
        "print(question.shape)\n",
        "\n",
        "# 產生虛擬answer資料：1000筆，每筆100個字(數字)\n",
        "answers = np.zeros(shape=(num_samples,answer_vocabulary_size),dtype='int32')\n",
        "\n",
        "for answer in answers:\n",
        "  answer[np.random.randint(answer_vocabulary_size)]=1\n",
        "print(answers.shape)\n",
        "\n",
        "# 訓練方法1：使用list將送入資料進行訓練\n",
        "model.fit([text,question],answers,epochs=10,batch_size=128)\n",
        "\n",
        "# 訓練方法2；使用dict將送入資料進行訓練，鍵為Input層的名稱，值為Numpy的值\n",
        "model.fit({'text':text,'question':question},answers,epochs=10,batch_size=128)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 100)\n",
            "(1000, 100)\n",
            "(1000, 500)\n",
            "Epoch 1/10\n",
            "8/8 [==============================] - 1s 128ms/step - loss: 6.2561 - acc: 0.0030\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 1s 126ms/step - loss: 6.1804 - acc: 0.0030\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 1s 112ms/step - loss: 6.1194 - acc: 0.0090\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 1s 137ms/step - loss: 6.0011 - acc: 0.0080\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 1s 115ms/step - loss: 5.8977 - acc: 0.0090\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 1s 115ms/step - loss: 5.7931 - acc: 0.0180\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 1s 114ms/step - loss: 5.7211 - acc: 0.0270\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 1s 126ms/step - loss: 5.6355 - acc: 0.0390\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 1s 116ms/step - loss: 5.5607 - acc: 0.0460\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 1s 113ms/step - loss: 5.4866 - acc: 0.0350\n",
            "Epoch 1/10\n",
            "8/8 [==============================] - 3s 128ms/step - loss: 5.4113 - acc: 0.0420\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 1s 115ms/step - loss: 5.3572 - acc: 0.0420\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 1s 114ms/step - loss: 5.2979 - acc: 0.0460\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 1s 117ms/step - loss: 5.2172 - acc: 0.0520\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 1s 117ms/step - loss: 5.1554 - acc: 0.0580\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 1s 114ms/step - loss: 5.0945 - acc: 0.0700\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 1s 115ms/step - loss: 5.0650 - acc: 0.0820\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 1s 114ms/step - loss: 4.9807 - acc: 0.0790\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 1s 117ms/step - loss: 4.9232 - acc: 0.0900\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 1s 115ms/step - loss: 4.8652 - acc: 0.1060\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6a2cf640d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9KII1gSQSgW"
      },
      "source": [
        "## 多輸出模型\n",
        "使用函數式api建構多個輸出的模型  \n",
        "在這情形下需要依據不同的輸出指定不同的損失函數來計算損失值  \n",
        "**由於梯度下降要求純量最小化，因此必須將這些損失值結合成單一數值才能訓練模型**\n",
        "  \n",
        "\n",
        "**例子**：以一個神經網路同時預測資料中的不同屬性  \n",
        "![pic 7-4](https://raw.githubusercontent.com/hank199599/deep_learning_keras_log/main/pictures/7-4.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJdkkIrnrA6M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "388b51c3-6e3b-4018-bfd7-5a4ab0922f81"
      },
      "source": [
        "from keras import layers,Input\n",
        "from keras.models import Model\n",
        "\n",
        "vocabulary_size = 50000\n",
        "num_income_groups = 10 #將收入分成10群\n",
        "\n",
        "posts_input = Input(shape=(None,),dtype='int32',name='posts')\n",
        "\n",
        "# 用函數式API將輸入向量傳入Embedding層，得到維度為256的崁入向量\n",
        "embedding_posts = layers.Embedding(vocabulary_size,256)(posts_input)\n",
        "print(embedding_posts.shape)\n",
        "\n",
        "# 以函數式API將砍入向量傳入一層層之中處理\n",
        "x = layers.Conv1D(128,5,activation='relu')(embedding_posts)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(256,5,activation='relu')(x)\n",
        "x = layers.Conv1D(256,5,activation='relu')(x)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(256,5,activation='relu')(x)\n",
        "x = layers.Conv1D(256,5,activation='relu')(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dense(128,activation='relu')(x)\n",
        "print(x.shape) # 走過一連串層後，x.shape為(?,128)\n",
        "\n",
        "#======================================================================#\n",
        "#將x向量分別送到3個輸入層\n",
        "#======================================================================#\n",
        "# 1. 預測年紀的輸出層：純量迴歸任務\n",
        "age_prediction = layers.Dense(1,name='age')(x)\n",
        "\n",
        "# 2. 預測收入族群的輸出層：多分類任務\n",
        "income_prediction = layers.Dense(num_income_groups,activation='softmax',name='income')(x)\n",
        "\n",
        "# 3. 預測性別的輸出層：二元分類任務\n",
        "gender_prediction = layers.Dense(1,activation='softmax',name='gender')(x)\n",
        "\n",
        "#======================================================================#\n",
        "#用輸入向量與輸出向量實例化Model物件\n",
        "#======================================================================#\n",
        "model = Model(posts_input,[age_prediction,income_prediction,gender_prediction])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, None, 256)\n",
            "(None, 128)\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "posts (InputLayer)              [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, None, 256)    12800000    posts[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, None, 128)    163968      embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1D)  (None, None, 128)    0           conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, None, 256)    164096      max_pooling1d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, None, 256)    327936      conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1D)  (None, None, 256)    0           conv1d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_8 (Conv1D)               (None, None, 256)    327936      max_pooling1d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_9 (Conv1D)               (None, None, 256)    327936      conv1d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_1 (GlobalM (None, 256)          0           conv1d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 128)          32896       global_max_pooling1d_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "age (Dense)                     (None, 1)            129         dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "income (Dense)                  (None, 10)           1290        dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gender (Dense)                  (None, 1)            129         dense_8[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 14,146,316\n",
            "Trainable params: 14,146,316\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omq-SahOW6_G"
      },
      "source": [
        "#### 計算整體誤差的方式\n",
        "在編譯模型時指定計算整體誤差的方式"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suaqrbTlXPFx"
      },
      "source": [
        "1. 使用損失串列 (loss list)：需照層的建立順序排序\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzHOorgeXJ9S"
      },
      "source": [
        "model.comile(optimizer='rmsprop',loss=['mse','categorical_crossentropy','binary_crossentropy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBpSSaiSXRR2"
      },
      "source": [
        "2. 使用損失字典 (loss dict)：需為輸出層指定名稱"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TD3T-6iXSyq"
      },
      "source": [
        "model.comile(optimizer='rmsprop',loss={'age':'mse','income':'categorical_crossentropy','gender':'binary_crossentropy'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2e9g3psaIB1"
      },
      "source": [
        "若模型間，有十分不平衡的損失值  \n",
        "易導致模型優先針對損失值較大者進行優化而忽略其他模型  \n",
        "我們可以在compile()加入**loss_weight**參數為損失值指定不同程度的重要性"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dX4dU9gkczcl"
      },
      "source": [
        "##### loss_weight參數設定\n",
        "* 均方誤差 (MAE)：3-5\n",
        "* 交叉熵 (cross-entropy):0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOmUsGyoctiP"
      },
      "source": [
        "1. 使用損失串列 (loss list)：需照層的建立順序排序\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGCxXxZMctiS"
      },
      "source": [
        "model.comile(optimizer='rmsprop',loss=['mse','categorical_crossentropy','binary_crossentropy'],loss_weights=[0.25,1.,10.])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1z7Rpg8cctiS"
      },
      "source": [
        "2. 使用損失字典 (loss dict)：需為輸出層指定名稱"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moHew-5WctiT"
      },
      "source": [
        "model.comile(optimizer='rmsprop',loss={'age':'mse','income':'categorical_crossentropy','gender':'binary_crossentropy'},loss_weights={'age':0.25,'income':1,'gender':10.})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV-psfmVdjgb"
      },
      "source": [
        "#### 訓練整體誤差的方式\n",
        "與多輸入模型的訓練方式一樣，可透過串列或字典將Numpy資料傳遞給模型進行訓練"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDIMf0c2djgo"
      },
      "source": [
        "1. 使用損失串列 (loss list)：需照層的建立順序排序\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znEXcWiwdjgo"
      },
      "source": [
        "model.fir(posts,[age_targets,income_targets,gender_targets],epochs=10,batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwNfOMtxdjgo"
      },
      "source": [
        "2. 使用損失字典 (loss dict)：需為輸出層指定名稱"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2ZDjRzHdjgp"
      },
      "source": [
        "model.fir(posts,{'age':age_targets,'income':income_targets,'gender':gender_targets},epochs=10,batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MyqP6g9e-q2"
      },
      "source": [
        "## 層的[有環無向圖](https://zh.wikipedia.org/wiki/%E6%9C%89%E5%90%91%E6%97%A0%E7%8E%AF%E5%9B%BE) Directed Acyclic Graphs\n",
        "![wiki_img](https://upload.wikimedia.org/wikipedia/commons/thumb/3/39/Directed_acyclic_graph_3.svg/356px-Directed_acyclic_graph_3.svg.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gK91xjoAfl6b"
      },
      "source": [
        "### Inception模組\n",
        "一種流行的卷積層經網路架構，主要受早期Network-in-Nwtwork神經網路架構的啟發。  \n",
        "**Inception神經網路主要由許多Inception模組所組成**  \n",
        "![pic 7-5](https://raw.githubusercontent.com/hank199599/deep_learning_keras_log/main/pictures/7-5.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQeXTbT4VmR8"
      },
      "source": [
        "#### 1x1卷積 (瓶頸層)\n",
        "可扮演降維的角色，有助於分解出channel特徵學習和空間特徵學習。  \n",
        "使所需的運算量下降並減少訓練時間。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vUulW6ZXlYE"
      },
      "source": [
        "#### 使用函數式API實作Inception模組\n",
        "在每個分支都有一個以相同步長進行採樣的層，  \n",
        "這是為了保持所有分支輸出張量大小必須相同所必需的設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPVpHIIoXqGs",
        "outputId": "4b7b39f4-488c-46e9-f863-f78a0f155ec2"
      },
      "source": [
        "from keras import layers,Input\n",
        "\n",
        "x = Input(batch_shape=(1000,28,28,256))\n",
        "print(x.shape)\n",
        "\n",
        "branch_a = layers.Conv2D(64,1,activation='relu',strides=2)(x) #使用步長參數=2的進行1/2採樣\n",
        "print(\"分支a\",branch_a.shape)\n",
        "\n",
        "branch_b = layers.Conv2D(64,1,activation='relu')(x) # 進行1x1逐點卷積，故shape大小不變\n",
        "branch_b = layers.Conv2D(128,1,activation='relu',strides=2,padding='same')(branch_b) # 進行3X3空間卷積，並使用步長參數=2 進行1/2採樣\n",
        "print(\"分支b\",branch_b.shape)\n",
        "\n",
        "branch_c = layers.AveragePooling2D(3,strides=2,padding='same')(x) # 採樣發生在平均池化中\n",
        "branch_c = layers.Conv2D(128,1,activation='relu',padding='same')(branch_c) \n",
        "print(\"分支c\",branch_c.shape)\n",
        "\n",
        "branch_d = layers.Conv2D(128,1,activation='relu')(x)\n",
        "branch_d = layers.Conv2D(128,3,activation='relu',padding='same')(branch_d) # 進行3X3空間卷積，並使用步長參數=2 進行1/2採樣\n",
        "branch_d = layers.Conv2D(128,3,activation='relu',strides=2,padding='same')(branch_d) # 進行3X3空間卷積，並使用步長參數=2 進行1/2採樣\n",
        "print(\"分支d\",branch_d.shape)\n",
        "\n",
        "#================================================================#\n",
        "#串接分支輸出以取得模組輸出\n",
        "output = layers.concatenate([branch_a,branch_b,branch_c,branch_d],axis=-1)\n",
        "print(output.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 28, 28, 256)\n",
            "分支a (1000, 14, 14, 64)\n",
            "分支b (1000, 14, 14, 128)\n",
            "分支c (1000, 14, 14, 128)\n",
            "分支d (1000, 14, 14, 128)\n",
            "(1000, 14, 14, 448)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2nhvMxEfrZg"
      },
      "source": [
        "### Xception模組\n",
        "將channel特徵和空間特徵的學習分離成邏輯極值的想法  \n",
        "屬於極端形式的Inception模組。  \n",
        "由於可以更有效率地使用模型參數，在大型資料有極有更好的執行性能與準確度。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opVYuZFnfrk5"
      },
      "source": [
        "### 殘差連接 Residual conections\n",
        "\n",
        "解決在大型神經網路易發生的**梯度消失**與**轉換瓶頸**  \n",
        "將殘插接加入到任何10層以上的模型都是有益的"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQjAwcoHHzKJ"
      },
      "source": [
        "#### 線性轉換 Linear Transformations\n",
        "\n",
        "存在一個函數(也可以視為矩陣) T 可以將 R^m 空間的向量(張量)對應(轉換)到 R^n 空間的向量(張量),只要 R^n 空間的任意向量 u v符合以下兩個條件即可稱此轉換為線性轉換：\n",
        "1. 可加性\n",
        "2. 齊次性"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sjhbx7U3HQb8",
        "outputId": "0104146c-0605-40fd-df64-72efacd85e5b"
      },
      "source": [
        "from keras import layers,Input\n",
        "\n",
        "x = Input(batch_shape=(1000,32,32,128)) # 定義4D張量 x\n",
        "y = layers.Conv2D(128,3,activation='relu',padding='same')(x)\n",
        "z = layers.Conv2D(128,3,activation='relu',padding='same')(y)\n",
        "\n",
        "op = layers.add([z,x])\n",
        "print(op.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 32, 32, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lq1o45AnKc8U"
      },
      "source": [
        "當啟動函數的shape大小不同時，可以透過線性轉換改變張量的shape  \n",
        "使他們的張量大小相同，再進行連接\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VV6o2tScKdXB",
        "outputId": "7de003ee-7d01-400f-e3c9-ebc66324e060"
      },
      "source": [
        "from keras import layers,Input\n",
        "\n",
        "x = Input(batch_shape=(1000,32,32,128)) # 定義4D張量 x\n",
        "y = layers.Conv2D(128,3,activation='relu',padding='same')(x)\n",
        "z = layers.Conv2D(128,3,activation='relu',padding='same')(y)\n",
        "print(z.shape)\n",
        "\n",
        "t = layers.MaxPool2D(2,strides=2)(z)\n",
        "print(t.shape)\n",
        "\n",
        "residual = layers.Conv2D(128,1,strides=2,padding='same')(x) # 對張量進行線性轉換以縮小採樣，並將channel降低盛與張量t相同的128\n",
        "print(residual.shape)\n",
        "\n",
        "op = layers.add([t,residual])\n",
        "print(op.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 32, 32, 128)\n",
            "(1000, 16, 16, 128)\n",
            "(1000, 16, 16, 128)\n",
            "(1000, 16, 16, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uP1tzkXAvRF6"
      },
      "source": [
        "## 層的權重共享\n",
        "藉由函數式API可以重複使用層物件的特性，建構出共享分支的模型  \n",
        "使得數個分支都擁有相同的知識並執行相同的操作  \n",
        "  \n",
        "例如：對話系統中，去除重複的語句"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVOojHqcv549"
      },
      "source": [
        "### 孿生LSTM (Siamese LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVDrdH0jvVie",
        "outputId": "40c8450c-f244-4eb5-c397-b111d66597d7"
      },
      "source": [
        "from keras import layers,Input\n",
        "from keras.models import Model\n",
        "\n",
        "lstm = layers.LSTM(32)\n",
        "left_input = Input(shape=(None,128))\n",
        "print(left_input.shape)\n",
        "left_output = lstm(left_input)\n",
        "print(left_output.shape)\n",
        "\n",
        "right_input = Input(shape=(None,128))\n",
        "print(right_input.shape)\n",
        "right_output = lstm(right_input)\n",
        "print(right_output.shape)\n",
        "\n",
        "merged = layers.concatenate([left_output,right_output],axis=-1) # 將向量串接\n",
        "print(merged.shape)\n",
        "\n",
        "predictions = layers.Dense(1,activation='sigmoid')(merged)\n",
        "model = Model([left_input,right_input],predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, None, 128)\n",
            "(None, 32)\n",
            "(None, None, 128)\n",
            "(None, 32)\n",
            "(None, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FyvoclY0lZ0"
      },
      "source": [
        "## 將模型作為層\n",
        "1. 將模型A放到模型B之中來使用  \n",
        "```python\n",
        "y=model(x)\n",
        "```\n",
        "2. 若模型有多個輸入和輸出，可以用張量list呼叫\n",
        "```python\n",
        "y1,y2 = model([x1,x2])\n",
        "```\n",
        "  \n",
        "當我們呼叫模型時，**會重複使用到模型的權重**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66T_-kiC5O-9"
      },
      "source": [
        "#### 範例 ： 3D人臉辨識\n",
        "不需要兩個獨立模型自左右鏡頭萃取視覺特徵，可以藉由同一個層來一起進行萃取"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjNiAvgd4sWb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0c026e2-e7b0-4b61-8a91-6c83430cd953"
      },
      "source": [
        "from keras import layers\n",
        "from keras import applications\n",
        "from keras import Input\n",
        "\n",
        "xception_base = applications.Xception(weights=None,include_top=False)\n",
        "\n",
        "left_input = Input(shape=(250,250,3))\n",
        "right_input = Input(shape=(250,250,3))\n",
        "\n",
        "left_features = xception_base(left_input)\n",
        "right_features = xception_base(right_input)\n",
        "\n",
        "print(left_features.shape)\n",
        "print(right_features.shape)\n",
        "\n",
        "merged_features = layers.concatenate([left_features,right_features],axis=-1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 8, 8, 2048)\n",
            "(None, 8, 8, 2048)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aElbXnxzuR3o"
      },
      "source": [
        "# 檢查[回呼(callback)](https://keras.io/zh/callbacks/)\n",
        "* 模型檢查點 (model checkpoint)：在訓練期間保存模型不同時間點的權重\n",
        "* 早期停止 (early stopping)：當驗證損失不再下降時中斷訓練\n",
        "* 在訓練期間動態調整某些參數的值\n",
        "* 紀錄訓練與驗證指標\n",
        "  \n",
        "內建回呼範例：\n",
        "```python\n",
        "keras.callbacks.ModelCheckpoint\n",
        "keras.callbacks.EarlyStopping\n",
        "keras.callbacks.LearningRateScheduler\n",
        "keras.callbacks.ReduceLROnPlateau\n",
        "keras.callbacks.CSVLogger\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQdvo9NgzmF0"
      },
      "source": [
        "## EarlyStopping 與 ModelCheckpoint 回呼\n",
        "若監控的指標在一定數量的訓練週期中停止改善，則使用EarlyStopping。  \n",
        "以避免重複進行相同的訓練。  \n",
        "通常會與ModelCheckpoint回呼偕同使用，讓我們在訓練過程中能不斷儲存模型。  \n",
        "```python\n",
        "import keras\n",
        "\n",
        "callbacks_list = [\n",
        "    keras.callbacks.EarlyStopping(monitor='val_acc',patience=1),\n",
        "    keras.callbacks.ModelCheckpoint(filepath='my_model.ht',monitor='val_acc',save_best_only=True)\n",
        "]\n",
        "\n",
        "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\n",
        "\n",
        "model.fit(x,y,validation_data=(x_val,y_val),epochs=10,batch_sizes=32,callbacks=callbacks_list)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZBTsu3_S3PN"
      },
      "source": [
        "## RedeuceLROnPlateau 回呼\n",
        "```python\n",
        "import keras\n",
        "\n",
        "callbacks_list = [keras.callbacks.RedeuceLROnPlateau(monitor='val_loss',factor=0.1,patience=10)]\n",
        "\n",
        "model.fit(x,y,validation_data=(x_val,y_val),epochs=10,batch_sizes=32,callbacks=callbacks_list)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l26ucIz4S3PO"
      },
      "source": [
        "## 撰寫自己的回呼  \n",
        "繼承Keras.callbacks.Callback類別，即可做出自己需要的method  \n",
        "\n",
        "* self.model : 呼叫回呼的模型物件\n",
        "* self.validation_data :  傳遞給fit作為驗證資料的數值\n",
        "\n",
        "```python\n",
        "import keras \n",
        "import numpy as np \n",
        "\n",
        "class ActivationLogger(keras.callbacks.Callback): # 繼承Callback類別\n",
        "\n",
        "    def set_model(self,model):\n",
        "        self.model = model\n",
        "        layer_outputs = [layers.output for layer in model.layers]\n",
        "        self.activations_model = keras.models.Model(model.input,layer_outputs)\n",
        "    \n",
        "    def on_epoch_end(self,epoch,logs=None):\n",
        "        if self.validation is None:\n",
        "            raise RuntimeError(Requires validation_data')\n",
        "        \n",
        "        validation_sample = self.validation_data[0][0:1]\n",
        "        activations = self.activations_model.predict(validation_sample)\n",
        "        f = open('validation_at_epoch',str(epoch)+'.npz','w')\n",
        "        np.save(f,activations)\n",
        "        f.close()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08TJMdPMS3PO"
      },
      "source": [
        "## TensorBoard\n",
        "TensorFlow視覺化框架→盡可能取模型執行過程中的詳細資訊  \n",
        "協助我們在訓練期間，直觀地監控模型內部的所有內容。  \n",
        "* 在訓練過程中顯示訓練指標\n",
        "* 視覺化模型架構\n",
        "* 視覺化啟動函數結果和梯度變化的直方圖\n",
        "* 以3D方式探索崁入向量"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhC2uIcZS3PP"
      },
      "source": [
        "### 使用Tensor內建的文字分類模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v7bhPk_S3PP",
        "outputId": "b82c4951-e5fa-4f03-849e-7f4e22df6fc4"
      },
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "max_features = 2000\n",
        "max_len = 500\n",
        "\n",
        "(x_train,y_train),(x_test,y_test) = imdb.load_data(num_words=max_features)\n",
        "x_train = sequence.pad_sequences(x_train,maxlen=max_len)\n",
        "x_test = sequence.pad_sequences(x_test,maxlen=max_len)\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(layers.Embedding(max_features,128,input_length=max_len,name='embed'))\n",
        "model.add(layers.Conv1D(32,7,activation='relu'))\n",
        "model.add(layers.MaxPool1D(5))\n",
        "model.add(layers.Conv1D(32,7,activation='relu'))\n",
        "model.add(layers.GlobalMaxPool1D())\n",
        "model.add(layers.Dense(1))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "D:\\Anacanda\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "D:\\Anacanda\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embed (Embedding)            (None, 500, 128)          256000    \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 494, 32)           28704     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 98, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 92, 32)            7200      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 291,937\n",
            "Trainable params: 291,937\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzxAeXpDS3PQ"
      },
      "source": [
        "### 使用TensorBoard回呼來訓練模型 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcV_CHLFS3PQ",
        "outputId": "846910d0-0623-41ac-a5e1-f2594b2a1366"
      },
      "source": [
        "callbacks_list = [\n",
        "    keras.callbacks.TensorBoard(log_dir='my_log_dir',histogram_freq=1,embeddings_freq=1)\n",
        "]\n",
        "\n",
        "history = model.fit(x_train,y_train,epochs=20,batch_size=128,validation_split=0.2,callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "157/157 [==============================] - 21s 80ms/step - loss: 0.7410 - acc: 0.5665 - val_loss: 0.4368 - val_acc: 0.8394\n",
            "Epoch 2/20\n",
            "157/157 [==============================] - 10s 66ms/step - loss: 0.4410 - acc: 0.8556 - val_loss: 2.8909 - val_acc: 0.5754\n",
            "Epoch 3/20\n",
            "157/157 [==============================] - 10s 66ms/step - loss: 0.4287 - acc: 0.8814 - val_loss: 0.6082 - val_acc: 0.8416\n",
            "Epoch 4/20\n",
            "157/157 [==============================] - 10s 67ms/step - loss: 0.3177 - acc: 0.9024 - val_loss: 0.5323 - val_acc: 0.8660\n",
            "Epoch 5/20\n",
            "157/157 [==============================] - 10s 67ms/step - loss: 0.3270 - acc: 0.9143 - val_loss: 0.7804 - val_acc: 0.8374\n",
            "Epoch 6/20\n",
            "157/157 [==============================] - 10s 67ms/step - loss: 0.2960 - acc: 0.9314 - val_loss: 0.6169 - val_acc: 0.8678\n",
            "Epoch 7/20\n",
            "157/157 [==============================] - 10s 67ms/step - loss: 0.2154 - acc: 0.9529 - val_loss: 0.7457 - val_acc: 0.8536\n",
            "Epoch 8/20\n",
            "157/157 [==============================] - 11s 67ms/step - loss: 0.1782 - acc: 0.9678 - val_loss: 0.7523 - val_acc: 0.8692\n",
            "Epoch 9/20\n",
            "157/157 [==============================] - 12s 74ms/step - loss: 0.1399 - acc: 0.9820 - val_loss: 0.7797 - val_acc: 0.8676\n",
            "Epoch 10/20\n",
            "157/157 [==============================] - 11s 70ms/step - loss: 0.1367 - acc: 0.9850 - val_loss: 0.9854 - val_acc: 0.8618\n",
            "Epoch 11/20\n",
            "157/157 [==============================] - 10s 66ms/step - loss: 0.1146 - acc: 0.9866 - val_loss: 1.5712 - val_acc: 0.8110\n",
            "Epoch 12/20\n",
            "157/157 [==============================] - 11s 67ms/step - loss: 0.1188 - acc: 0.9869 - val_loss: 1.0155 - val_acc: 0.8680\n",
            "Epoch 13/20\n",
            "157/157 [==============================] - 11s 67ms/step - loss: 0.1020 - acc: 0.9908 - val_loss: 1.1545 - val_acc: 0.8522\n",
            "Epoch 14/20\n",
            "157/157 [==============================] - 10s 66ms/step - loss: 0.1090 - acc: 0.9903 - val_loss: 1.1747 - val_acc: 0.8612\n",
            "Epoch 15/20\n",
            "157/157 [==============================] - 10s 66ms/step - loss: 0.1141 - acc: 0.9897 - val_loss: 1.1334 - val_acc: 0.8690\n",
            "Epoch 16/20\n",
            "157/157 [==============================] - 10s 67ms/step - loss: 0.1016 - acc: 0.9925 - val_loss: 1.1841 - val_acc: 0.8634\n",
            "Epoch 17/20\n",
            "157/157 [==============================] - 10s 66ms/step - loss: 0.1060 - acc: 0.9908 - val_loss: 1.2251 - val_acc: 0.8640\n",
            "Epoch 18/20\n",
            "157/157 [==============================] - 10s 67ms/step - loss: 0.1069 - acc: 0.9911 - val_loss: 1.2626 - val_acc: 0.8650\n",
            "Epoch 19/20\n",
            "157/157 [==============================] - 10s 66ms/step - loss: 0.0898 - acc: 0.9930 - val_loss: 1.6146 - val_acc: 0.8336\n",
            "Epoch 20/20\n",
            "157/157 [==============================] - 10s 66ms/step - loss: 0.1073 - acc: 0.9912 - val_loss: 1.2923 - val_acc: 0.8634\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UVgV3cRS3PQ",
        "outputId": "4c811c1d-fb64-4af9-e3bb-4d7ff0640986"
      },
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(model,to_file='model.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOI5S2qzS3PR"
      },
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(model,show_shapes=True,to_file='model.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqGn8v1btnRm"
      },
      "source": [
        "# 模型最大化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XI6UjNu2tuAL"
      },
      "source": [
        "## 批次正規化\n",
        "讓機器學習模型看到不同樣本間的相同之處，有助於模型學習和概括新的資料。  \n",
        "* 資料減去平均值使之以0為中心，除以標準差"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSTjT8Rd6Fjq"
      },
      "source": [
        "### 批次量標準化\n",
        "在訓練過程中一所檢視道的批次量資料的軍職和變異數，  \n",
        "持續保持內部的一個**指數移動平均值**  \n",
        "用於協助梯度傳遞，可以確保資訊不變形並利於建構更深的神經網路。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cHhSqXZtyiq"
      },
      "source": [
        "## 深度可分離卷積 SeperableConv2D\n",
        "\n",
        "在其輸入的每一個channel進行空間卷積(3x3卷積)  \n",
        "使空間特徵的學習與channel特徵的學習分開進行。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEVi5H1wt3rm"
      },
      "source": [
        "# 超參數優化\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqXzD_CO7zBY"
      },
      "source": [
        "## 超參數 (hyperparameters)\n",
        "\n",
        "在建構深度學習模型時，於**架構等級的參數**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGfC2DaF796E"
      },
      "source": [
        "## 優化超參數的流程\n",
        "1. 選擇一組超參數(自動執行)\n",
        "2. 建構對應的模型\n",
        "3. 以訓練資料加以訓練，並測量驗證資料的最終成效\n",
        "4. 選擇要嘗試的下一組超參數(自動)\n",
        "5. 重複進行\n",
        "6. 測量測試資料的成效\n",
        "  \n",
        "在實務上，執行上述步驟的關鍵是所使用的演算法\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bOIsGvy8ivY"
      },
      "source": [
        "## 更新超參數的癥結點\n",
        "1. 計算回饋訊號的成本相對昂貴\n",
        "2. 想養類非梯度優化技術，而相對難以獲得成效"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5ECBgoF85sA"
      },
      "source": [
        "## 適用於超參數優化的Python函式庫\n",
        "* [Hyperopt](https://github.com/hyperopt/hyperopt)\n",
        "* [Hyperas](https://github.com/maxpumperla/hyperas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5j2vapTMt5hV"
      },
      "source": [
        "# 模型集成 (model ensembling)\n",
        "將多個模型的預測結果整合起來，以產生更好的預測。  \n",
        "每個模型都會因檢視資料的不同面向進行預測，因而獲得不同面向的見解。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpmapaOM9t67"
      },
      "source": [
        "## 多樣性 (diverity)\n",
        "若每個模型有不同的取向(biased in different ways)，\n",
        "能使偏差相互抵銷，使模型集成的結果更加健全與準確。"
      ]
    }
  ]
}