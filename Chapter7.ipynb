{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter7.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNxSC67JQeH2aCvhL3XsU3I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hank199599/deep_learning_keras_log/blob/main/Chapter7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWlaJkQvPsuX"
      },
      "source": [
        "# 超越序列式模型\n",
        "\n",
        "* 單輸入模型\n",
        "* 多輸入模型\n",
        "* 殘差連接層(residual connections)層：透過特徵圖(張量)相加，將先前的資訊重新注入下游資料流"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7itMEtqQFLK"
      },
      "source": [
        "## [函數式API](https://keras.io/guides/functional_api/)\n",
        "\n",
        "使用Input()方法來檢立一個張量，並將張量直接傳入層(layer)或模型(model)之中，  \n",
        "取得處理後的結果張量。\n",
        "```python\n",
        "from keras import Input,layers\n",
        "\n",
        "input_tensor = Input(shape=(32,)) #建立一個輸入張量\n",
        "print(input_tensor.shape)\n",
        "\n",
        "dense = layers.Dense(16,activation='relu') #建立一個Dense層，並將其想像成一個函數\n",
        "output_tensor = dense(input_tensor) # 將張量輸入層函數，他會回傳經處理後的結果張亮\n",
        "print(output_tensor.shape)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUAIZlg0SRhq"
      },
      "source": [
        "### 序列式 與 函數式 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOQISgnqVhgt"
      },
      "source": [
        "序列式(Sequential)建立模型  \n",
        "![pic 7-1](https://raw.githubusercontent.com/hank199599/deep_learning_keras_log/main/pictures/7-1.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQwm5uoASXRv",
        "outputId": "c9bf25d3-1e51-45e8-bccc-9f339be2ac89"
      },
      "source": [
        "from keras.models import Sequential,Model\n",
        "from keras import layers,Input\n",
        "\n",
        "model=Sequential()\n",
        "model.add(layers.Dense(32,activation='relu',input_shape=(64,)))\n",
        "model.add(layers.Dense(32,activation='relu'))\n",
        "model.add(layers.Dense(32,activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                1056      \n",
            "=================================================================\n",
            "Total params: 4,192\n",
            "Trainable params: 4,192\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIYaPQBPV9BF"
      },
      "source": [
        "#### 函數式(API)建立模型\n",
        "透過建立**Model物件**，\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHYkLSg1Vf5l",
        "outputId": "6f9a4152-9c7c-420b-b21f-c034d3c757bf"
      },
      "source": [
        "input_tensor = Input(shape=(64,)) # 建立一個初始張量\n",
        "\n",
        "x = layers.Dense(32,activation='relu')(input_tensor)\n",
        "\n",
        "y = layers.Dense(32,activation='relu')(x)\n",
        "\n",
        "output_tensor = layers.Dense(10,activation='softmax')(y)\n",
        "\n",
        "model = Model(input_tensor,output_tensor)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 64)]              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 3,466\n",
            "Trainable params: 3,466\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rwg5AP8dbsu"
      },
      "source": [
        "如果用完全不相干的輸入和輸出張量去建構模型。  \n",
        "因為Keras找不到相關資訊，導致執行時會生錯誤。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "rr8SHU7adqko",
        "outputId": "8c94d955-66ea-47b0-bebd-a8778122ed1f"
      },
      "source": [
        "unrelated_input = Input(shape=(32,))\n",
        "bad_model = model = Model(unrelated_input,output_tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-be4c35b96e38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0munrelated_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbad_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munrelated_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFunctional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     nodes, nodes_by_depth, layers, _ = _map_graph_network(\n\u001b[0;32m--> 204\u001b[0;31m         self.inputs, self.outputs)\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m    988\u001b[0m                              \u001b[0;34m'The following previous layers '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m                              \u001b[0;34m'were accessed without issue: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m                              str(layers_with_complete_input))\n\u001b[0m\u001b[1;32m    991\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0mcomputable_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\") at layer \"dense_3\". The following previous layers were accessed without issue: []"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A4ZYHw6d8qO"
      },
      "source": [
        "在編譯、訓練或驗證此Model物件時，API的功能與序列式模型相同"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "451uIm70d8yn",
        "outputId": "968c8768-6839-42a2-80ee-7a68451c942c"
      },
      "source": [
        "model.compile(optimizer='rmsprop',loss='categorical_crossentropy')\n",
        "import numpy as np\n",
        "\n",
        "x_train = np.random.random((1000,64))\n",
        "y_train = np.random.random((1000,10))\n",
        "\n",
        "# 將訓練輸入模型進行訓練\n",
        "model.fit(x_train,y_train,epochs=10,batch_size=128)\n",
        "score = model.evaluate(x_train,y_train)\n",
        "print(score) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 1s 2ms/step - loss: 12.2086\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 12.1521\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 12.6796\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 13.6005\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 14.9342\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 16.7674\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 18.6711\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 21.3209\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 24.0460\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 27.5270\n",
            "32/32 [==============================] - 0s 931us/step - loss: 30.1749\n",
            "30.174882888793945\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofuO1uReenDJ"
      },
      "source": [
        "## 多輸入模型\n",
        "\n",
        "*[範例]*：典型的問答模型  \n",
        "必須針對問題產生出答案，可透過softmax分類器針對某些事件先定義好詞彙並輸出答案  \n",
        "![pic 7-3](https://raw.githubusercontent.com/hank199599/deep_learning_keras_log/main/pictures/7-3.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDZpMCc5et4k",
        "outputId": "d407d4fe-3b0c-4bc5-a7b0-bce0e2c35431"
      },
      "source": [
        "from keras import Model \n",
        "from keras import layers\n",
        "from keras import Input\n",
        "\n",
        "text_vocabulary_size = 10000\n",
        "question_vocabulary_size = 10000\n",
        "answer_vocabulary_size = 500\n",
        "\n",
        "text_input = Input(shape=(None,),dtype='int32',name='text')\n",
        "embedded_text = layers.Embedding(text_vocabulary_size,64)(text_input)\n",
        "print(embedded_text.shape)\n",
        "encoded_text = layers.LSTM(32)(embedded_text)\n",
        "print(encoded_text.shape)\n",
        "\n",
        "question_input = Input(shape=(None,),dtype='int32',name='question')\n",
        "embedded_question = layers.Embedding(question_vocabulary_size,32)(question_input)\n",
        "print(embedded_question.shape)\n",
        "encoded_question = layers.LSTM(16)(embedded_question)\n",
        "print(encoded_question.shape)\n",
        "\n",
        "concatenated = layers.concatenate([encoded_question,encoded_text],axis=1)\n",
        "print(concatenated.shape)\n",
        "\n",
        "answer = layers.Dense(answer_vocabulary_size,activation='softmax')(concatenated)\n",
        "print(answer.shape)\n",
        "\n",
        "model = Model([text_input,question_input],answer)\n",
        "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, None, 64)\n",
            "(None, 32)\n",
            "(None, None, 32)\n",
            "(None, 16)\n",
            "(None, 48)\n",
            "(None, 500)\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "question (InputLayer)           [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "text (InputLayer)               [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 32)     320000      question[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 64)     640000      text[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 16)           3136        embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 32)           12416       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 48)           0           lstm_1[0][0]                     \n",
            "                                                                 lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 500)          24500       concatenate[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 1,000,052\n",
            "Trainable params: 1,000,052\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9l-spDSntiE"
      },
      "source": [
        "### 訓練雙輸入模型的方法\n",
        "1. 為模型準備Numpy陣列\n",
        "2. 選擇下列兩種方式進行訓練 \n",
        "①將 Numpy 陣列資料組成串列(list)做為輸入進行訓練。  \n",
        "②建立一個字典(dict), 將輸入透過鍵(輸入名稱),對應到值(Numpy陣列資料)。當然,此方法只有在為輸入命名時才可用,例如上面程式中的第7行\n",
        "```python\n",
        "Input(., name = 'text,\n",
        "```\n",
        "我們就可以建立 dict:\n",
        "```python\n",
        "{'text': Numpy 資料}  \n",
        "```\n",
        "做為此輸入張量對應的 Numpy 資料。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lDzxjippD6O",
        "outputId": "4d167007-138d-461a-f0c3-0a9ae2d84582"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "num_samples = 1000\n",
        "max_length = 100\n",
        "\n",
        "# 產生虛擬text資料：1000筆，每筆100個字(數字)\n",
        "text = np.random.randint(1,text_vocabulary_size,size = (num_samples,max_length))\n",
        "print(text.shape)\n",
        "\n",
        "# 產生虛擬question資料：1000筆，每筆100個字(數字)\n",
        "question = np.random.randint(1,question_vocabulary_size,size = (num_samples,max_length))\n",
        "print(question.shape)\n",
        "\n",
        "# 產生虛擬answer資料：1000筆，每筆100個字(數字)\n",
        "answers = np.zeros(shape=(num_samples,answer_vocabulary_size),dtype='int32')\n",
        "\n",
        "for answer in answers:\n",
        "  answer[np.random.randint(answer_vocabulary_size)]=1\n",
        "print(answers.shape)\n",
        "\n",
        "# 訓練方法1：使用list將送入資料進行訓練\n",
        "model.fit([text,question],answers,epochs=10,batch_size=128)\n",
        "\n",
        "# 訓練方法2；使用dict將送入資料進行訓練，鍵為Input層的名稱，值為Numpy的值\n",
        "model.fit({'text':text,'question':question},answers,epochs=10,batch_size=128)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 100)\n",
            "(1000, 100)\n",
            "(1000, 500)\n",
            "Epoch 1/10\n",
            "8/8 [==============================] - 1s 128ms/step - loss: 6.2561 - acc: 0.0030\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 1s 126ms/step - loss: 6.1804 - acc: 0.0030\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 1s 112ms/step - loss: 6.1194 - acc: 0.0090\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 1s 137ms/step - loss: 6.0011 - acc: 0.0080\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 1s 115ms/step - loss: 5.8977 - acc: 0.0090\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 1s 115ms/step - loss: 5.7931 - acc: 0.0180\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 1s 114ms/step - loss: 5.7211 - acc: 0.0270\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 1s 126ms/step - loss: 5.6355 - acc: 0.0390\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 1s 116ms/step - loss: 5.5607 - acc: 0.0460\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 1s 113ms/step - loss: 5.4866 - acc: 0.0350\n",
            "Epoch 1/10\n",
            "8/8 [==============================] - 3s 128ms/step - loss: 5.4113 - acc: 0.0420\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 1s 115ms/step - loss: 5.3572 - acc: 0.0420\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 1s 114ms/step - loss: 5.2979 - acc: 0.0460\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 1s 117ms/step - loss: 5.2172 - acc: 0.0520\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 1s 117ms/step - loss: 5.1554 - acc: 0.0580\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 1s 114ms/step - loss: 5.0945 - acc: 0.0700\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 1s 115ms/step - loss: 5.0650 - acc: 0.0820\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 1s 114ms/step - loss: 4.9807 - acc: 0.0790\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 1s 117ms/step - loss: 4.9232 - acc: 0.0900\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 1s 115ms/step - loss: 4.8652 - acc: 0.1060\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6a2cf640d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9KII1gSQSgW"
      },
      "source": [
        "## 多輸出模型\n",
        "使用函數式api建構多個輸出的模型  \n",
        "在這情形下需要依據不同的輸出指定不同的損失函數來計算損失值  \n",
        "**由於梯度下降要求純量最小化，因此必須將這些損失值結合成單一數值才能訓練模型**\n",
        "  \n",
        "\n",
        "**例子**：以一個神經網路同時預測資料中的不同屬性  \n",
        "![pic 7-4](https://raw.githubusercontent.com/hank199599/deep_learning_keras_log/main/pictures/7-4.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJdkkIrnrA6M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "388b51c3-6e3b-4018-bfd7-5a4ab0922f81"
      },
      "source": [
        "from keras import layers,Input\n",
        "from keras.models import Model\n",
        "\n",
        "vocabulary_size = 50000\n",
        "num_income_groups = 10 #將收入分成10群\n",
        "\n",
        "posts_input = Input(shape=(None,),dtype='int32',name='posts')\n",
        "\n",
        "# 用函數式API將輸入向量傳入Embedding層，得到維度為256的崁入向量\n",
        "embedding_posts = layers.Embedding(vocabulary_size,256)(posts_input)\n",
        "print(embedding_posts.shape)\n",
        "\n",
        "# 以函數式API將砍入向量傳入一層層之中處理\n",
        "x = layers.Conv1D(128,5,activation='relu')(embedding_posts)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(256,5,activation='relu')(x)\n",
        "x = layers.Conv1D(256,5,activation='relu')(x)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(256,5,activation='relu')(x)\n",
        "x = layers.Conv1D(256,5,activation='relu')(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dense(128,activation='relu')(x)\n",
        "print(x.shape) # 走過一連串層後，x.shape為(?,128)\n",
        "\n",
        "#======================================================================#\n",
        "#將x向量分別送到3個輸入層\n",
        "#======================================================================#\n",
        "# 1. 預測年紀的輸出層：純量迴歸任務\n",
        "age_prediction = layers.Dense(1,name='age')(x)\n",
        "\n",
        "# 2. 預測收入族群的輸出層：多分類任務\n",
        "income_prediction = layers.Dense(num_income_groups,activation='softmax',name='income')(x)\n",
        "\n",
        "# 3. 預測性別的輸出層：二元分類任務\n",
        "gender_prediction = layers.Dense(1,activation='softmax',name='gender')(x)\n",
        "\n",
        "#======================================================================#\n",
        "#用輸入向量與輸出向量實例化Model物件\n",
        "#======================================================================#\n",
        "model = Model(posts_input,[age_prediction,income_prediction,gender_prediction])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, None, 256)\n",
            "(None, 128)\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "posts (InputLayer)              [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, None, 256)    12800000    posts[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, None, 128)    163968      embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1D)  (None, None, 128)    0           conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, None, 256)    164096      max_pooling1d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, None, 256)    327936      conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1D)  (None, None, 256)    0           conv1d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_8 (Conv1D)               (None, None, 256)    327936      max_pooling1d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_9 (Conv1D)               (None, None, 256)    327936      conv1d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_1 (GlobalM (None, 256)          0           conv1d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 128)          32896       global_max_pooling1d_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "age (Dense)                     (None, 1)            129         dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "income (Dense)                  (None, 10)           1290        dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gender (Dense)                  (None, 1)            129         dense_8[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 14,146,316\n",
            "Trainable params: 14,146,316\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omq-SahOW6_G"
      },
      "source": [
        "#### 計算整體誤差的方式\n",
        "在編譯模型時指定計算整體誤差的方式"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suaqrbTlXPFx"
      },
      "source": [
        "1. 使用損失串列 (loss list)：需照層的建立順序排序\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzHOorgeXJ9S"
      },
      "source": [
        "model.comile(optimizer='rmsprop',loss=['mse','categorical_crossentropy','binary_crossentropy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBpSSaiSXRR2"
      },
      "source": [
        "2. 使用損失字典 (loss dict)：需為輸出層指定名稱"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TD3T-6iXSyq"
      },
      "source": [
        "model.comile(optimizer='rmsprop',loss={'age':'mse','income':'categorical_crossentropy','gender':'binary_crossentropy'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2e9g3psaIB1"
      },
      "source": [
        "若模型間，有十分不平衡的損失值  \n",
        "易導致模型優先針對損失值較大者進行優化而忽略其他模型  \n",
        "我們可以在compile()加入**loss_weight**參數為損失值指定不同程度的重要性"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dX4dU9gkczcl"
      },
      "source": [
        "##### loss_weight參數設定\n",
        "* 均方誤差 (MAE)：3-5\n",
        "* 交叉熵 (cross-entropy):0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOmUsGyoctiP"
      },
      "source": [
        "1. 使用損失串列 (loss list)：需照層的建立順序排序\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGCxXxZMctiS"
      },
      "source": [
        "model.comile(optimizer='rmsprop',loss=['mse','categorical_crossentropy','binary_crossentropy'],loss_weights=[0.25,1.,10.])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1z7Rpg8cctiS"
      },
      "source": [
        "2. 使用損失字典 (loss dict)：需為輸出層指定名稱"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moHew-5WctiT"
      },
      "source": [
        "model.comile(optimizer='rmsprop',loss={'age':'mse','income':'categorical_crossentropy','gender':'binary_crossentropy'},loss_weights={'age':0.25,'income':1,'gender':10.})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV-psfmVdjgb"
      },
      "source": [
        "#### 訓練整體誤差的方式\n",
        "與多輸入模型的訓練方式一樣，可透過串列或字典將Numpy資料傳遞給模型進行訓練"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDIMf0c2djgo"
      },
      "source": [
        "1. 使用損失串列 (loss list)：需照層的建立順序排序\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znEXcWiwdjgo"
      },
      "source": [
        "model.fir(posts,[age_targets,income_targets,gender_targets],epochs=10,batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwNfOMtxdjgo"
      },
      "source": [
        "2. 使用損失字典 (loss dict)：需為輸出層指定名稱"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2ZDjRzHdjgp"
      },
      "source": [
        "model.fir(posts,{'age':age_targets,'income':income_targets,'gender':gender_targets},epochs=10,batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MyqP6g9e-q2"
      },
      "source": [
        "## 層的[有環無向圖](https://zh.wikipedia.org/wiki/%E6%9C%89%E5%90%91%E6%97%A0%E7%8E%AF%E5%9B%BE) Directed Acyclic Graphs\n",
        "![wiki_img](https://upload.wikimedia.org/wikipedia/commons/thumb/3/39/Directed_acyclic_graph_3.svg/356px-Directed_acyclic_graph_3.svg.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gK91xjoAfl6b"
      },
      "source": [
        "### Inception模組\n",
        "一種流行的卷積層經網路架構，主要受早期Network-in-Nwtwork神經網路架構的啟發。  \n",
        "**Inception神經網路主要由許多Inception模組所組成**  \n",
        "![pic 7-5](https://raw.githubusercontent.com/hank199599/deep_learning_keras_log/main/pictures/7-5.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQeXTbT4VmR8"
      },
      "source": [
        "#### 1x1卷積 (瓶頸層)\n",
        "可扮演降維的角色，有助於分解出channel特徵學習和空間特徵學習。  \n",
        "使所需的運算量下降並減少訓練時間。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vUulW6ZXlYE"
      },
      "source": [
        "#### 使用函數式API實作Inception模組\n",
        "在每個分支都有一個以相同步長進行採樣的層，  \n",
        "這是為了保持所有分支輸出張量大小必須相同所必需的設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPVpHIIoXqGs",
        "outputId": "4b7b39f4-488c-46e9-f863-f78a0f155ec2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras import layers,Input\n",
        "\n",
        "x = Input(batch_shape=(1000,28,28,256))\n",
        "print(x.shape)\n",
        "\n",
        "branch_a = layers.Conv2D(64,1,activation='relu',strides=2)(x) #使用步長參數=2的進行1/2採樣\n",
        "print(\"分支a\",branch_a.shape)\n",
        "\n",
        "branch_b = layers.Conv2D(64,1,activation='relu')(x) # 進行1x1逐點卷積，故shape大小不變\n",
        "branch_b = layers.Conv2D(128,1,activation='relu',strides=2,padding='same')(branch_b) # 進行3X3空間卷積，並使用步長參數=2 進行1/2採樣\n",
        "print(\"分支b\",branch_b.shape)\n",
        "\n",
        "branch_c = layers.AveragePooling2D(3,strides=2,padding='same')(x) # 採樣發生在平均池化中\n",
        "branch_c = layers.Conv2D(128,1,activation='relu',padding='same')(branch_c) \n",
        "print(\"分支c\",branch_c.shape)\n",
        "\n",
        "branch_d = layers.Conv2D(128,1,activation='relu')(x)\n",
        "branch_d = layers.Conv2D(128,3,activation='relu',padding='same')(branch_d) # 進行3X3空間卷積，並使用步長參數=2 進行1/2採樣\n",
        "branch_d = layers.Conv2D(128,3,activation='relu',strides=2,padding='same')(branch_d) # 進行3X3空間卷積，並使用步長參數=2 進行1/2採樣\n",
        "print(\"分支d\",branch_d.shape)\n",
        "\n",
        "#================================================================#\n",
        "#串接分支輸出以取得模組輸出\n",
        "output = layers.concatenate([branch_a,branch_b,branch_c,branch_d],axis=-1)\n",
        "print(output.shape)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 28, 28, 256)\n",
            "分支a (1000, 14, 14, 64)\n",
            "分支b (1000, 14, 14, 128)\n",
            "分支c (1000, 14, 14, 128)\n",
            "分支d (1000, 14, 14, 128)\n",
            "(1000, 14, 14, 448)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2nhvMxEfrZg"
      },
      "source": [
        "### Xception模組\n",
        "將channel特徵和空間特徵的學習分離成邏輯極值的想法  \n",
        "屬於極端形式的Inception模組。  \n",
        "由於可以更有效率地使用模型參數，在大型資料有極有更好的執行性能與準確度。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opVYuZFnfrk5"
      },
      "source": [
        "### 殘差連接 Residual conections\n",
        "\n",
        "解決在大型神經網路易發生的**梯度消失**與**轉換瓶頸**  \n",
        "將殘插接加入到任何10層以上的模型都是有益的"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQjAwcoHHzKJ"
      },
      "source": [
        "#### 線性轉換 Linear Transformations\n",
        "\n",
        "存在一個函數(也可以視為矩陣) T 可以將 R^m 空間的向量(張量)對應(轉換)到 R^n 空間的向量(張量),只要 R^n 空間的任意向量 u v符合以下兩個條件即可稱此轉換為線性轉換：\n",
        "1. 可加性\n",
        "2. 齊次性"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sjhbx7U3HQb8",
        "outputId": "0104146c-0605-40fd-df64-72efacd85e5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras import layers,Input\n",
        "\n",
        "x = Input(batch_shape=(1000,32,32,128)) # 定義4D張量 x\n",
        "y = layers.Conv2D(128,3,activation='relu',padding='same')(x)\n",
        "z = layers.Conv2D(128,3,activation='relu',padding='same')(y)\n",
        "\n",
        "op = layers.add([z,x])\n",
        "print(op.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 32, 32, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lq1o45AnKc8U"
      },
      "source": [
        "當啟動函數的shape大小不同時，可以透過線性轉換改變張量的shape  \n",
        "使他們的張量大小相同，再進行連接\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VV6o2tScKdXB",
        "outputId": "7de003ee-7d01-400f-e3c9-ebc66324e060",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras import layers,Input\n",
        "\n",
        "x = Input(batch_shape=(1000,32,32,128)) # 定義4D張量 x\n",
        "y = layers.Conv2D(128,3,activation='relu',padding='same')(x)\n",
        "z = layers.Conv2D(128,3,activation='relu',padding='same')(y)\n",
        "print(z.shape)\n",
        "\n",
        "t = layers.MaxPool2D(2,strides=2)(z)\n",
        "print(t.shape)\n",
        "\n",
        "residual = layers.Conv2D(128,1,strides=2,padding='same')(x) # 對張量進行線性轉換以縮小採樣，並將channel降低盛與張量t相同的128\n",
        "print(residual.shape)\n",
        "\n",
        "op = layers.add([t,residual])\n",
        "print(op.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 32, 32, 128)\n",
            "(1000, 16, 16, 128)\n",
            "(1000, 16, 16, 128)\n",
            "(1000, 16, 16, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uP1tzkXAvRF6"
      },
      "source": [
        "### 層的權重共享\n",
        "藉由函數式API可以重複使用層物件的特性，建構出共享分支的模型  \n",
        "使得數個分支都擁有相同的知識並執行相同的操作  \n",
        "  \n",
        "例如：對話系統中，去除重複的語句"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVOojHqcv549"
      },
      "source": [
        "#### 孿生LSTM (Siamese LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVDrdH0jvVie",
        "outputId": "40c8450c-f244-4eb5-c397-b111d66597d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras import layers,Input\n",
        "from keras.models import Model\n",
        "\n",
        "lstm = layers.LSTM(32)\n",
        "left_input = Input(shape=(None,128))\n",
        "print(left_input.shape)\n",
        "left_output = lstm(left_input)\n",
        "print(left_output.shape)\n",
        "\n",
        "right_input = Input(shape=(None,128))\n",
        "print(right_input.shape)\n",
        "right_output = lstm(right_input)\n",
        "print(right_output.shape)\n",
        "\n",
        "merged = layers.concatenate([left_output,right_output],axis=-1) # 將向量串接\n",
        "print(merged.shape)\n",
        "\n",
        "predictions = layers.Dense(1,activation='sigmoid')(merged)\n",
        "model = Model([left_input,right_input],predictions)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, None, 128)\n",
            "(None, 32)\n",
            "(None, None, 128)\n",
            "(None, 32)\n",
            "(None, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}