{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOaaZEXT36r4kqn+TfPIBet",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hank199599/deep_learning_keras_log/blob/main/Chapter1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUodBERmwR2r"
      },
      "source": [
        "# 人工智慧發展\r\n",
        "\r\n",
        "* 1950年代：定義人工智慧「能自動化執行一般人類的智慧工作」\r\n",
        "* 1950 - 1980年代：符號式AI\r\n",
        "* 2014年：批次正規化(batch normalization)\r\n",
        "* 2015年：殘差連接(residual connections)\r\n",
        "* 2016年：深度可分離卷積(depth-wise seperable convolutions)\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uP5XxhOxC_-"
      },
      "source": [
        "# 人工智慧分類\r\n",
        "* 符號式AI (symbolic AL)\r\n",
        " * 解決規則清楚的問題 \r\n",
        "* 機器學習 (machine learning)\r\n",
        " * 分析機 (Analytical Engine)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuewiLLlv5EI"
      },
      "source": [
        "# 機器學習\r\n",
        "從提供的資料及對應的標準答案去發現規則，並依此規則自動化地處理後續新發現且沒有標準答案的資料。\r\n",
        "* 輸入資料點\r\n",
        "* 標準答案\r\n",
        "* 評估演算法執行結果好壞的方法\r\n",
        "  \r\n",
        "**核心問題**：如何有意義地轉換資料  \r\n",
        "表示法(representations)：用不同的資料來檢視資料，將資料重新表述或編碼\r\n",
        "  \r\n",
        "![1-3](https://github.com/hank199599/deep_learning_keras_log/blob/main/pictures/1-3.png?raw=true)\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3BifLLChNOA"
      },
      "source": [
        "## 深度學習的相關名詞\r\n",
        "* 層(layer)：藉由權重參數(parameter)來和輸入資料進行運算以執行資料轉換的工作\r\n",
        "* 權重(weight)：\r\n",
        "* 學習：為神經網路的每一層找到適當的權重值\r\n",
        "* **損失函數(loss function)**/目標函數(objective functions)：取得神經網路預測結果和標準答案，評估輸出與標準答案的差距 (損失分數/差距分數)\r\n",
        "* 優化器(optimizer,最佳化函數)：使用損失函數做為回饋訊號來微調各層的權重，使每次學習的損失函數逐步降低\r\n",
        "* 反向傳播演算法(Backpropagation)：一種於深度學習中的一個核心演算法。用於梯度下降最佳化(gradient-descent optimization)  \r\n",
        "![](https://github.com/hank199599/deep_learning_keras_log/blob/main/pictures/1-2.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CA2hDZENntIt"
      },
      "source": [
        "# 機率建模 Probabilistic modeling\r\n",
        "##最早的機器學習的型式\r\n",
        "\r\n",
        "* [單純貝式演算法 Naive Bayes theorem](https://colab.research.google.com/github/hank199599/data_science_from_scratch_reading_log/blob/main/Chapter13.ipynb)\r\n",
        "* [邏輯斯迴歸 Logisitc Regression](https://colab.research.google.com/github/hank199599/data_science_from_scratch_reading_log/blob/main/Chapter16.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_Qy2qMSqnNS"
      },
      "source": [
        "# SVM (Support Vector Machine,1995)\r\n",
        "屬於一種 Kernel methods 分類演算法  \r\n",
        "  \r\n",
        "目標：在兩種類別的資料點間，找到**最佳決策邊界(desicion boundaries)**。\r\n",
        "原理：將訓練資料區隔開來的最佳曲面，曲面兩邊對應到不同的類別。  \r\n",
        "一旦找到決策邊界，只需檢查新的資料點落在決策邊界的哪一側，就能知道他們屬於哪一類。\r\n",
        "1. 把資料映射到一個高維表示法(高維空間),然後在此空間找出最佳決策 邊界,一般這個決策邊界是一個超曲面\r\n",
        "2. 在找超曲面時,超曲面要位於兩類資料點之間的中線  \r\n",
        "這步驟稱為**最大化邊界(maximizing the margin)**  \r\n",
        "也就是讓曲面分別和兩類資料點保有最大距離,這使得當新的資料點被填入空間時(要分類時), 決策邊界可以適當的將新資料點予以分類(編註:因為兩邊都保有最大距離,因此保有 空間餘裕 (margin). 比較不會分類錯誤,如果餘裕太小,例如決策邊界偏到某一邊,那可能資料點的特徵值只差一點點就分錯邊了。  \r\n",
        "例如：進行腫瘤是良性還是惡性的分類時"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qlg6H15_si_9"
      },
      "source": [
        "## kernal function  \r\n",
        "將初始空間中的任一兩點映射到目標空間對應點之間的「距離」"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cPxwI7WuaOy"
      },
      "source": [
        "# [決策樹](https://colab.research.google.com/github/hank199599/data_science_from_scratch_reading_log/blob/main/Chapter17.ipynb)\r\n",
        "* 分類樹 (classification tree):輸出某個分類結果\r\n",
        "* 回歸樹 (regression tree): 輸出某個數值結果  \r\n",
        "  \r\n",
        "需要決定以何種順序建立決策樹，決策樹的每個階段都能為我們消除某些可能性。  \r\n",
        "# 隨機森林\r\n",
        "建立多個決策樹，並將他們的輸出組合起來。\r\n",
        "* 數顆**分類**決策樹：進行投票\r\n",
        "* 數顆**迴歸**決策樹：取所有預測值的平均值\r\n",
        "\r\n",
        "利用隨機取樣，來訓練每一顆決策樹。  \r\n",
        "  \r\n",
        "**優點**：\r\n",
        "* 由於每顆決策樹都是利用不同的資料建立起來的，每棵樹之間會有些許不同。\r\n",
        "* 提供隨機性的來源→改變選擇的**最佳屬性**\r\n",
        "\r\n",
        "# 梯度提升機器(Gradient Boosting Machines,GBM)\r\n",
        "由一個弱預測模型集合而成的機器學習技術，他使用梯度提升方式，透過迭代訓練逐步加入新的模型以克服先前模型的弱點，最終形成一個強預測的模型。"
      ]
    }
  ]
}