{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMw+BElHzFTD5ts4d+v05XX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hank199599/deep_learning_keras_log/blob/main/Chapter5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQWyzLYUr-SL"
      },
      "source": [
        "# MNIST 影像訓練卷積神經網路"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCkjGWvZttfo"
      },
      "source": [
        "from keras.datasets import mnist\r\n",
        "from keras.utils import to_categorical\r\n",
        "\r\n",
        "model = models.Sequential()\r\n",
        "\r\n",
        "model.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1)))\r\n",
        "model.add(layers.MaxPooling2D((2,2)))\r\n",
        "model.add(layers.Conv2D(64,(3,3),activation='relu'))\r\n",
        "model.add(layers.MaxPooling2D((2,2)))\r\n",
        "model.add(layers.Conv2D(64,(3,3),activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkGGIC4iwD7j"
      },
      "source": [
        "## 參數的算法\r\n",
        "參數 = 過濾器長*寬*輸入通道數*過濾器個數+過濾器個數"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCdc0l7pvs3F",
        "outputId": "2fbd5958-779e-47db-fb42-ede1c33f425a"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
            "=================================================================\n",
            "Total params: 55,744\n",
            "Trainable params: 55,744\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gi-x21DwWhA"
      },
      "source": [
        "最後一個Conv2D層輸出的2D張量必須送到接觸的分類器神經網路  \r\n",
        "故需要將3D張量展平為1D張量，才能進行傳遞"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjG4QgfnwWEA"
      },
      "source": [
        "model.add(layers.Flatten())\r\n",
        "model.add(layers.Dense(64,activation='relu'))\r\n",
        "model.add(layers.Dense(10,activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEvF5Al5xBxX",
        "outputId": "2b004011-ac5b-4e4b-a9ec-cbfafc11d7c6"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                36928     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 97,482\n",
            "Trainable params: 97,482\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaifUbsltw0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5287e96-76be-4f2f-f20b-a8c20e33ef5f"
      },
      "source": [
        "from keras import layers\r\n",
        "from keras import models\r\n",
        "\r\n",
        "\r\n",
        "(train_images,train_labels),(test_images,test_labels) = mnist.load_data()\r\n",
        "\r\n",
        "train_images = train_images.reshape((60000,28,28,1))\r\n",
        "train_images = train_images.astype('float32')/255\r\n",
        "\r\n",
        "test_images = test_images.reshape((10000,28,28,1))\r\n",
        "test_images = test_images.astype('float32')/255\r\n",
        "\r\n",
        "train_labels = to_categorical(train_labels)\r\n",
        "test_labels = to_categorical(test_labels)\r\n",
        "\r\n",
        "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\r\n",
        "\r\n",
        "model.fit(train_images,train_labels,epochs=5,batch_size=64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "938/938 [==============================] - 44s 46ms/step - loss: 0.4381 - accuracy: 0.8591\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 43s 46ms/step - loss: 0.0572 - accuracy: 0.9824\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 43s 46ms/step - loss: 0.0359 - accuracy: 0.9892\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 43s 45ms/step - loss: 0.0267 - accuracy: 0.9918\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.0214 - accuracy: 0.9935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4025cbefd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0YroQUbxPl-"
      },
      "source": [
        "運用測試資料來驗證準確度"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iV8GMn1pxS2j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25712a7e-5e21-495f-950d-913a6ab9c5e3"
      },
      "source": [
        "test_loss,test_acc = model.evaluate(test_images,test_labels)\r\n",
        "test_acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0287 - accuracy: 0.9912\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9911999702453613"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNeKxMRN9dgf"
      },
      "source": [
        "# 卷積層"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZSDl0FAxfn1"
      },
      "source": [
        "## 比較\r\n",
        "* **密集層**：學習特徵空間中全域的Pattern\r\n",
        "* **卷積層**：學習局部的pattern\r\n",
        "\r\n",
        "> 特徵映射圖亦被稱作特徵圖：他本身是一個抽象映射動作  \r\n",
        "  \r\n",
        "![pic5-1](https://github.com/hank199599/deep_learning_keras_log/blob/main/pictures/5-1.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_4CnfDw8kKw"
      },
      "source": [
        "## 定義\r\n",
        "* 從輸入採樣的區塊大小\r\n",
        "* 輸出特徵圖的深度  \r\n",
        "　　　　　↓ filter數量　　　　 ↓ 以tuple或list傳入\r\n",
        "```python\r\n",
        "Conv2D(output_depth,(widow_height,window_width))\r\n",
        "```  \r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIjriqb7-M1W"
      },
      "source": [
        "## 運作原理\r\n",
        "1. 在3D輸入特徵圖上滑動的小窗格，萃取窗格上的3D區塊的特徵  \r\n",
        "2. 將每個3D區塊轉換成做張量**shape=(output_depth,)**的1D張量\r\n",
        "3. 將所有向量依照空間上的位置排列重新組裝成**shape=(height,width,output_depth)**的3D輸出特徵圖  \r\n",
        "\r\n",
        "> 輸出特徵圖中的每個空間位置和輸入特徵圖中的相同位置相對應  \r\n",
        "\r\n",
        "![pic5-2](https://github.com/hank199599/deep_learning_keras_log/blob/main/pictures/5-2.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJ-00S4k_2iC"
      },
      "source": [
        "## 可能的問題\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quDIh0vpAKQn"
      },
      "source": [
        "### 邊界效應 border effec\r\n",
        "![pic5-3](https://github.com/hank199599/deep_learning_keras_log/blob/main/pictures/5-3.png?raw=true)  \r\n",
        "透過窗格的滑動萃取特徵圖的同時，  \r\n",
        "會使輸出的向量維度發生縮減的情形。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5j23E1OqBEJq"
      },
      "source": [
        "**解決方式**：填補法(padding)  \r\n",
        "在輸入特徵圖的每一側增加適當數量的列和行，以便讓每個輸入圖塊都可以讓卷積層的移動窗格掃描到。\r\n",
        "```\r\n",
        "在Conv2D層中，使用padding參數來設定  \r\n",
        "* vaild ；不用填補\r\n",
        "* same ： 使用填補方式使輸出輸入具有相同的寬度和高度\r\n",
        "```\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQcVwkI5AK_j"
      },
      "source": [
        "### 步長(stride)\r\n",
        "控制窗格移動的間距  \r\n",
        "依此方式進行取樣的卷積層被稱作「**步長設定卷積層**(strided convolutions)」\r\n",
        "> 即步長大於1的卷積層\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAi2AR8iQ5JA"
      },
      "source": [
        "# Maxpooling\r\n",
        "從輸入特徵圖中做採樣並輸出樣本的最大值。  \r\n",
        "他並非用卷積核(convolution kernel)張量積的方式來轉換的局部區塊\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmXBz9IiVFT3"
      },
      "source": [
        "from keras import layers\r\n",
        "from keras import models\r\n",
        "model_no_max_pool = models.Sequential()\r\n",
        "model_no_max_pool.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1)))\r\n",
        "model_no_max_pool.add(layers.Conv2D(64,(3,3),activation='relu'))\r\n",
        "model_no_max_pool.add(layers.Conv2D(64,(3,3),activation='relu'))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TkY0ToqVfcb",
        "outputId": "22c92de0-eb69-42f8-c695-3cfdfd0ce47b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_no_max_pool.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 22, 22, 64)        36928     \n",
            "=================================================================\n",
            "Total params: 55,744\n",
            "Trainable params: 55,744\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "In1fVserZoE8"
      },
      "source": [
        "# 少量資料從頭訓練\r\n",
        "易發生 **overfiting**\r\n",
        "* 資料擴增法 (data augmentation)\r\n",
        "* 預先訓練神經網路的特徵萃取法 (feature extration with a pretrained network)\r\n",
        "* 微調預先訓練神經網路法 (fine-tuning a pretrained network)\r\n",
        "[這段操作在本機端上執行]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HMJHQHuoLan"
      },
      "source": [
        ""
      ]
    }
  ]
}