{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter8.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM1psZ52X+LFGkm2GrrSU5T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hank199599/deep_learning_keras_log/blob/main/Chapter8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rk7iIb3vESSa"
      },
      "source": [
        "# 使用LSTM產生文字資料"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgIYeJZ1H7p0"
      },
      "source": [
        "## 生成序列資料\n",
        "訓練神經網路為先前輸入的序列資料產生接續的資料，  \n",
        "該神經網路被稱為語言模型，他會去捕捉語言的淺在空間(latent space)。  \n",
        "* 條件資料(conditioning data)：初始的文字字串"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuPckWvOI07l"
      },
      "source": [
        "## 字元等級的語言模型 (charactor-level neural language model)\n",
        "使用LSTM層，從文字資料庫(text corpus)中萃取N個字元的字串作為輸入，  \n",
        "並訓練模型預設第N+1個字元。  \n",
        "  \n",
        "**模型的輸出**：所有可能的字元經softmax運算後的結果  \n",
        "![pic 8-1](https://raw.githubusercontent.com/hank199599/deep_learning_keras_log/main/pictures/8-1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ck1jKBS7KLYq"
      },
      "source": [
        "## 取樣策略的重要性\n",
        "1. **greedy sampling** (貪婪取樣)：在所有可能字元中選擇最可能的下一個字元，但易導致重複的預測字串\n",
        "2. **stochastic sampling** (隨機取樣): 自下一個字元的機率分布中取樣，並導入隨機性"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCKjjfFaNLbC"
      },
      "source": [
        "### 控制隨機性 control the amount of randomness\n",
        "在極端情形下，若分布不具隨機性會使抽樣結果則使該方法無效化\n",
        "* 分布機率具最大熵(entorpy)：每個字元具有相同的可能性並具有最大的隨機性\n",
        "* 分布機率具最小熵(entorpy)：字元分布幾乎不具備隨機性"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6ue5XqHOfcc"
      },
      "source": [
        "#### softmax temperature：取樣機率分布熵的指標\n",
        "代表下一個字元的不確定性"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7ynyHSMQtWP"
      },
      "source": [
        "##### 範例\n",
        "三個可能會出現的字元 a,b,c  \n",
        "a 出現機率為 80%  \n",
        "b,c 出現機率為 20%   \n",
        "  \n",
        "建立一個function針對不同的temperature設定，對機率分布重新加權並計算出新的機率分布"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaifUbsltw0v"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def reweight_distribution(original_distribution,temperature=0.5):\n",
        "  distribution = np.log(original_distribution)/temperature\n",
        "  distribution = np.exp(distribution)\n",
        "  return distribution / np.sum(distribution) #傳回重新加權\n",
        "  \n",
        "  # 因為重新加權後，機率分布之總和可能不再是1。因此再將其除以總合以滿足總合為1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0hnFtivTD04"
      },
      "source": [
        "ori_dstri = np.array([0.8,0.1,0.1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TnT9CCxTM_A",
        "outputId": "816f4174-458b-4e37-abc3-c92fb2b48972"
      },
      "source": [
        "new_dstri = reweight_distribution(ori_dstri,temperature=0.01)\n",
        "print(new_dstri)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.00000000e+00 4.90909347e-91 4.90909347e-91]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzvt2Ap9TXxa",
        "outputId": "62b9dbba-64d5-47dd-f2dc-7ab499cf3c4f"
      },
      "source": [
        "new_dstri = reweight_distribution(ori_dstri,temperature=2)\n",
        "print(new_dstri)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.58578644 0.20710678 0.20710678]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC_h8QEkTawB",
        "outputId": "5900dd33-569a-4634-87cf-3d1ae2d74e82"
      },
      "source": [
        "new_dstri = reweight_distribution(ori_dstri,temperature=10)\n",
        "print(new_dstri)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.38102426 0.30948787 0.30948787]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z65Ng74kQn8k"
      },
      "source": [
        "![pic 8-2](https://raw.githubusercontent.com/hank199599/deep_learning_keras_log/main/pictures/8-2.png)  \n",
        "使用較高temperature使亂度上升，產生更高的隨機性  \n",
        "相反地，越低的溫度會使廳選出的樣本偏向特定一方"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEUYNRk4UgAz"
      },
      "source": [
        "## 實現字元級LSTM文字資料生成 (本機端上操作)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4cWXsyJVBRP",
        "outputId": "5d3ee51d-1e88-4ef9-a40f-05f5591b35fb"
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "path = keras.utils.get_file(\n",
        "    'nietzsche.txt',\n",
        "    origin = 'https://s3.amazonaws.com/text-datasets/nietzsche.txt'\n",
        ")\n",
        "text = open(path).read().lower()\n",
        "print('Corpus length:',len(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
            "606208/600901 [==============================] - 0s 1us/step\n",
            "Corpus length: 600893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfAeU87ZVpg4"
      },
      "source": [
        "以每3個字元作為間隔，萃取出一段段長度為maxlen的部分重疊序列資料"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1-BR-tCV109"
      },
      "source": [
        "### 向量化字元序列"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWCwlECsV9Pb",
        "outputId": "7af42eb5-d73b-45f3-cc63-2a73430d6f61"
      },
      "source": [
        "maxlen = 60\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0,len(text)-maxlen,step):\n",
        "  sentences.append(text[i:i+maxlen])\n",
        "  next_chars.append(text[i+maxlen])\n",
        "print('Number of sequences:',len(sentences))\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "print('Unique charactors:',len(chars))\n",
        "\n",
        "# 將各個字元對應到\"chars\"串列中的索引值，成為字典格式\n",
        "char_indices = dict((char,char.index(char)) for char in chars)\n",
        "\n",
        "# 將字元經One-Hot編碼為二元陣列\n",
        "print('Vectorization....')\n",
        "x = np.zeros((len(sentences),maxlen,len(chars)),dtype=np.bool)\n",
        "y = np.zeros((len(sentences),len(chars)),dtype=np.bool)\n",
        "\n",
        "for i,sentence in enumerate(sentences):\n",
        "  for t , char in enumerate(chars):\n",
        "    x[i,t,char_indices[char]] = 1\n",
        "  y[i,char_indices[next_chars[i]]] = 1\n",
        "\n",
        "print(x.shape)\n",
        "print(y.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sequences: 200278\n",
            "Unique charactors: 57\n",
            "Vectorization....\n",
            "(200278, 60, 57)\n",
            "(200278, 57)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCkZiKQCh3TT"
      },
      "source": [
        "## 建立神經網路"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0_KAxF_xUlB"
      },
      "source": [
        "from keras import layers \n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(layers.LSTM(128,input_shape=(maxlen,len(chars))))\n",
        "model.add(layers.Dense(len(chars),activation='softmax')) # 預測字元種類，共57種"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuOq119eyw8Q"
      },
      "source": [
        "#### 模型編譯設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXCJCz7Yy0PX"
      },
      "source": [
        "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy',optimizer=optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPf8Wn0Dh7US"
      },
      "source": [
        "### 訓練語言模型並從中取樣\n",
        "1. 給定到目前為止生成的文字，從模型中繼下一個字元的機率分布\n",
        "2. 將分布重新調整到一特定的temperature\n",
        "3. 根據重新加權的分布隨機取樣取得下一個字元\n",
        "4. 在現有的文字字尾加入新字元"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ypXfBibzHt_"
      },
      "source": [
        "def sample(preds,temperature=1.0):\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  # ======== 重新加權計算熵 ===============\n",
        "  preds = np.log(preds) / temperature\n",
        "  exp_preds = np.exp(preds)\n",
        "  preds = exp_preds / np.sum(exp_preds)\n",
        "  \n",
        "  probas = np.random.multinomial(1,preds,1)\n",
        "  return np.argmax(probas) # 取出多項式分佈的結果"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZwAxtlU1a0a"
      },
      "source": [
        "#### 循環文字的生成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9VXZ_Fe1fy_"
      },
      "source": [
        "import random \n",
        "import sys\n",
        "\n",
        "for epoch in range(1,60):\n",
        "  print('epoch',epoch)\n",
        "  model.fit(x,y,batch_size=128,epochs=1)\n",
        "\n",
        "  # 隨機選擇文本中的某段60個字元的文字 (初始文字)\n",
        "  start_index = random.randint(0,len(text)-maxlen-1)\n",
        "  generated_text = text[start_index:start_index+maxlen]\n",
        "  \n",
        "  print('-----random initial text:\"',generated_text,'\"')\n",
        "\n",
        "\n",
        "  for temperature in [0.2,0.5,1.0,1.2]:\n",
        "    print('-----temperature:',temperature)\n",
        "    sys.stdout.write(generated_text)\n",
        "\n",
        "    # 每個temperature生成400個字元\n",
        "    for i in range(400):\n",
        "      sampled = np.zeros((1,maxlen,len(chars)))\n",
        "      for t,char in enumerate(generated_text):\n",
        "        sampled[0,t,char_indices[char]] = 1.\n",
        "      \n",
        "      preds = model.predict(sampled,verbose=0)[0]\n",
        "      next_index = sample(preds,temperature)\n",
        "      next_char = chars[next_index]\n",
        "      generated_text += next_char\n",
        "      generated_text = generated_text[1:]\n",
        "      sys.stdout.write(next_char)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y067sLgYEdfj"
      },
      "source": [
        "# DeepDream\n",
        "![10 iterations of applying DeepDream](https://upload.wikimedia.org/wikipedia/commons/8/89/Aurelia-aurita-3-0009.jpg)\n",
        "一種藝術圖片修改技術，使用**反向卷積神經網路學習**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWoz1XKBhjvY"
      },
      "source": [
        "### 載入預先訓練的[Inception V3](https://arxiv.org/pdf/1512.00567v3.pdf) 模型\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvXyENbyE8Yi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce2f35dc-649b-43c9-871e-e4e343121fa3"
      },
      "source": [
        "from tensorflow.keras.applications import inception_v3\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "K.set_learning_phase(0) # 終止所有訓練相關的操作\n",
        "model = inception_v3.InceptionV3(weights='imagenet',include_top=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:434: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVChzx3uidvG"
      },
      "source": [
        "## 計算損失\n",
        "選擇一組高層的啟動函式，取其輸出的L2 Norm。  \n",
        "並以它們的加權總合做為損失函數  \n",
        "藉由**梯度上升法**尋求最大化的損失"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQdlVjeVlb6E"
      },
      "source": [
        "建立字典並將層名稱對應到其損失函數的**貢獻係數**(value)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esNedi44llZM"
      },
      "source": [
        "layer_contributions={\n",
        "  'mixed2':0.2,\n",
        "  'mixed3':2.,  \n",
        "  'mixed4':2.,\n",
        "  'mixed5':1.5,\n",
        "}"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2J6sOtsImJ61"
      },
      "source": [
        "### 定義損失最大化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tz-DXTp-mKIu"
      },
      "source": [
        "layer_dict = dict([(layer.name,layer) for layer in model.layers])\n",
        "\n",
        "loss = K.variable(0.)\n",
        "for layer_name in layer_contributions:\n",
        "  coeff = layer_contributions[layer_name]\n",
        "  activation = layer_dict[layer_name].output\n",
        "  scaling = K.prod(K.cast(K.shape(activation),'float32'))\n",
        "\n",
        "  loss = loss + coeff * K.sum(K.square(activation[:,2:-2,2:-2,:])) / scaling"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-IXzglvp0W0"
      },
      "source": [
        "### 梯度上升處理程序"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaFEWJ9zp8F-",
        "outputId": "5b12dec9-91d1-462b-8cd4-b4af8e76897a"
      },
      "source": [
        "dream = model.input\n",
        "print(dream.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, None, None, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7j6CMlqqC1U"
      },
      "source": [
        "\n",
        "grads = K.gradients(loss,dream)[0]\n",
        "grads /= K.maximum(K.mean(K.abs(grads)),1e-7) # 正規化梯度\n",
        "\n",
        "# 在給定輸入圖片的情況下，自定一個Keras已取得損失值與梯度值\n",
        "outputs = [loss,grads]\n",
        "fetch_loss_and_grads = K.function([dream],outputs)\n",
        "\n",
        "def eval_loss_and_grads(x):\n",
        "  outs = fetch_loss_and_grads([x])\n",
        "  loss_value = outs[0]\n",
        "  grad_value = outs[1]\n",
        "  return loss_value,grad_value\n",
        "\n",
        "def gradient_ascent(x,iterations,step,max_loss=None):\n",
        "  for i in range(iterations):\n",
        "    if loss_value is not None and loss_value > max_loss:\n",
        "      break\n",
        "    print('...Loss value ar',i,':',loss_value)\n",
        "    print('...grad value ar',i,':',grad_values)\n",
        "    x += step*grad_values\n",
        "  return"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZG_Zjan5wOPs"
      },
      "source": [
        "### DeepDream 演算法\n",
        "1. 定義一個處理圖片的比例(Scale)串列\n",
        "2. 每個連續的比例比前一個比例大1.4倍，在每次梯度上升後將圖片放大40%在繼續進行梯度上升\n",
        "為避免每次連續放大後損失大量圖片細節，將損失的細節重新融入圖片  \n",
        "![pic 8-3](https://raw.githubusercontent.com/hank199599/deep_learning_keras_log/main/pictures/8-3.png) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQT7ni9Kyumt"
      },
      "source": [
        "import scipy\n",
        "from keras.preprocessing import image \n",
        "\n",
        "# 對葡片進行預處理\n",
        "def preprocess_image(image_path):\n",
        "  img = image.load_img(image_path)\n",
        "  img = img.img_to_array(img)\n",
        "  print(img.shape)\n",
        "  img = np.expand_dims(img,axis=0)\n",
        "  print(img.shape)\n",
        "  img = inception_v3.preprocess_input(img)\n",
        "  return img\n",
        "\n",
        "# 將Inception V3所做的預處理進行反向操作，轉回圖片格式\n",
        "def deprocess_image(x):\n",
        "  if K.image_data_format()=='channels_first':\n",
        "    x = x.reshape((3,x.shape[2],x.shape[3]))\n",
        "    x = x.transpose((1,2,0))\n",
        "  else:\n",
        "    x = x.reshape((x,shape[1],x.shape[2],3))\n",
        "  x /= 2.\n",
        "  x *= 0.5\n",
        "  x *= 255.\n",
        "  x = np.clip(x,0,255).astype('unit8') # 將數字限制在0-255之間\n",
        "  return x\n",
        "\n",
        "# 進行圖片比例的縮放\n",
        "def resize_img(img,size):\n",
        "  img = np.copy(img)\n",
        "  factors = (1,\n",
        "        float(size[0])/img.shape[1],\n",
        "        float(size[1])/img.shape[2],\n",
        "        1\n",
        "        )\n",
        "  return scipy.ndimage.zoom(img,factors,order=1) #以樣條插值法的技術對圖片進行縮放\n",
        "\n",
        "\n",
        "# 儲存圖片，於儲存前反轉Inception V3所做的預處理\n",
        "def save_img(img,fname):\n",
        "  pil_img = deprocess_image(np.copy(img))\n",
        "  scipy.misc.imsave(fname,pil_img)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTmvbmsP2Ett"
      },
      "source": [
        "### 在不同的連續比例的圖片上執行梯度上升"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "848svqBq2CPS",
        "outputId": "bb1af4d9-cfd7-4cb2-a644-a0ded24a1321"
      },
      "source": [
        "step = 0.01\n",
        "num_octave = 3\n",
        "octave_scale = 1.4\n",
        "iterations = 20\n",
        "max_loss = 10.\n",
        "\n",
        "base_image_path = 'original_photo_deep_dream.jpg'\n",
        "img = preprocess_image(base_image_path) # 載入圖片並進行預處理\n",
        "original_shape = img.shape[1:3]\n",
        "successive_shapes = [original_shape]\n",
        "\n",
        "for i in range(1,num_octave):\n",
        "  shape = tuple([int(dim / (octave_scale ** i)) for dim in original_shape])\n",
        "  successive_shapes.append(shape)\n",
        "successive_shapes = successive_shapes[::-1] # 反轉寬高比例list，使他們按照大小順序遞增\n",
        "\n",
        "original_img = np.copy(img)\n",
        "shrunk_original_img = resize_img(img,successive_shapes[0])\n",
        "\n",
        "for shape in successive_shapes: # 開始逐次放大圖片\n",
        "  print('Preprocessing image shape',shape)\n",
        "  img = resize_img(img,shape)\n",
        "  img = gradient_ascent(img,iterations=iterations,step=step,max_loss=max_loss) # 執行梯度上升\n",
        "  upscaled_shrunk_original_img = resize_img(shrunk_original_img,shape)\n",
        "\n",
        "  same_size_original = resize_img(original_img,shape) # 將原始圖片縮小至目前比例(大→小)\n",
        "  lost_detail = same_size_original - upscaled_shrunk_original_img # 相減求得損失的細節\n",
        "  img += lost_detail # 將損失的細節放回圖片中\n",
        "  shrunk_original_img = resize_img(original_img,shape)\n",
        "  save_img(img,frame='dream_at_scale_'+str(shape)+'.png')\n",
        "\n",
        "save_img(img,fname='final_dream.png')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-0981df5671b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mbase_image_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'original_photo_deep_dream.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_image_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 載入圖片並進行預處理\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0moriginal_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msuccessive_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moriginal_shape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-db7ebf8bc0a7>\u001b[0m in \u001b[0;36mpreprocess_image\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 對葡片進行預處理\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    298\u001b[0m   \"\"\"\n\u001b[1;32m    299\u001b[0m   return image.load_img(path, grayscale=grayscale, color_mode=color_mode,\n\u001b[0;32m--> 300\u001b[0;31m                         target_size=target_size, interpolation=interpolation)\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'original_photo_deep_dream.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebiXVEodEhGR"
      },
      "source": [
        "# 神經風格轉換"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxPM68CzE9rj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9HFRy4cEkz7"
      },
      "source": [
        "# 使用變分自編碼器 Variational Autoencoders 生成圖像"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KRfIi8rE-Fe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bm6Kv0p9EwN7"
      },
      "source": [
        "# 生成對抗神經網路簡介 Generative Adversarial Network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldasFvZ_E-pk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}