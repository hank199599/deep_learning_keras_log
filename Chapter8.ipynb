{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter8.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPak5l1FPPRm5TfCDnqMnc1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hank199599/deep_learning_keras_log/blob/main/Chapter8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rk7iIb3vESSa"
      },
      "source": [
        "# 使用LSTM產生文字資料"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgIYeJZ1H7p0"
      },
      "source": [
        "## 生成序列資料\n",
        "訓練神經網路為先前輸入的序列資料產生接續的資料，  \n",
        "該神經網路被稱為語言模型，他會去捕捉語言的淺在空間(latent space)。  \n",
        "* 條件資料(conditioning data)：初始的文字字串"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuPckWvOI07l"
      },
      "source": [
        "## 字元等級的語言模型 (charactor-level neural language model)\n",
        "使用LSTM層，從文字資料庫(text corpus)中萃取N個字元的字串作為輸入，  \n",
        "並訓練模型預設第N+1個字元。  \n",
        "  \n",
        "**模型的輸出**：所有可能的字元經softmax運算後的結果  \n",
        "![pic 8-1](https://raw.githubusercontent.com/hank199599/deep_learning_keras_log/main/pictures/8-1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ck1jKBS7KLYq"
      },
      "source": [
        "## 取樣策略的重要性\n",
        "1. **greedy sampling** (貪婪取樣)：在所有可能字元中選擇最可能的下一個字元，但易導致重複的預測字串\n",
        "2. **stochastic sampling** (隨機取樣): 自下一個字元的機率分布中取樣，並導入隨機性"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCKjjfFaNLbC"
      },
      "source": [
        "### 控制隨機性 control the amount of randomness\n",
        "在極端情形下，若分布不具隨機性會使抽樣結果則使該方法無效化\n",
        "* 分布機率具最大熵(entorpy)：每個字元具有相同的可能性並具有最大的隨機性\n",
        "* 分布機率具最小熵(entorpy)：字元分布幾乎不具備隨機性"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6ue5XqHOfcc"
      },
      "source": [
        "#### softmax temperature：取樣機率分布熵的指標\n",
        "代表下一個字元的不確定性"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7ynyHSMQtWP"
      },
      "source": [
        "##### 範例\n",
        "三個可能會出現的字元 a,b,c  \n",
        "a 出現機率為 80%  \n",
        "b,c 出現機率為 20%   \n",
        "  \n",
        "建立一個function針對不同的temperature設定，對機率分布重新加權並計算出新的機率分布"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaifUbsltw0v"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def reweight_distribution(original_distribution,temperature=0.5):\n",
        "  distribution = np.log(original_distribution)/temperature\n",
        "  distribution = np.exp(distribution)\n",
        "  return distribution / np.sum(distribution) #傳回重新加權\n",
        "  \n",
        "  # 因為重新加權後，機率分布之總和可能不再是1。因此再將其除以總合以滿足總合為1"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0hnFtivTD04"
      },
      "source": [
        "ori_dstri = np.array([0.8,0.1,0.1])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TnT9CCxTM_A",
        "outputId": "816f4174-458b-4e37-abc3-c92fb2b48972"
      },
      "source": [
        "new_dstri = reweight_distribution(ori_dstri,temperature=0.01)\n",
        "print(new_dstri)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.00000000e+00 4.90909347e-91 4.90909347e-91]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzvt2Ap9TXxa",
        "outputId": "62b9dbba-64d5-47dd-f2dc-7ab499cf3c4f"
      },
      "source": [
        "new_dstri = reweight_distribution(ori_dstri,temperature=2)\n",
        "print(new_dstri)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.58578644 0.20710678 0.20710678]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC_h8QEkTawB",
        "outputId": "5900dd33-569a-4634-87cf-3d1ae2d74e82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "new_dstri = reweight_distribution(ori_dstri,temperature=10)\n",
        "print(new_dstri)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.38102426 0.30948787 0.30948787]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z65Ng74kQn8k"
      },
      "source": [
        "![pic 8-2](https://raw.githubusercontent.com/hank199599/deep_learning_keras_log/main/pictures/8-2.png)  \n",
        "使用較高temperature使亂度上升，產生更高的隨機性  \n",
        "相反地，越低的溫度會使廳選出的樣本偏向特定一方"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEUYNRk4UgAz"
      },
      "source": [
        "## 實現字元級LSTM文字資料生成 (本機端上操作)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4cWXsyJVBRP",
        "outputId": "5d3ee51d-1e88-4ef9-a40f-05f5591b35fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "path = keras.utils.get_file(\n",
        "    'nietzsche.txt',\n",
        "    origin = 'https://s3.amazonaws.com/text-datasets/nietzsche.txt'\n",
        ")\n",
        "text = open(path).read().lower()\n",
        "print('Corpus length:',len(text))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
            "606208/600901 [==============================] - 0s 1us/step\n",
            "Corpus length: 600893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfAeU87ZVpg4"
      },
      "source": [
        "以每3個字元作為間隔，萃取出一段段長度為maxlen的部分重疊序列資料"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1-BR-tCV109"
      },
      "source": [
        "### 向量化字元序列"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWCwlECsV9Pb",
        "outputId": "7af42eb5-d73b-45f3-cc63-2a73430d6f61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "maxlen = 60\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0,len(text)-maxlen,step):\n",
        "  sentences.append(text[i:i+maxlen])\n",
        "  next_chars.append(text[i+maxlen])\n",
        "print('Number of sequences:',len(sentences))\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "print('Unique charactors:',len(chars))\n",
        "\n",
        "# 將各個字元對應到\"chars\"串列中的索引值，成為字典格式\n",
        "char_indices = dict((char,char.index(char)) for char in chars)\n",
        "\n",
        "# 將字元經One-Hot編碼為二元陣列\n",
        "print('Vectorization....')\n",
        "x = np.zeros((len(sentences),maxlen,len(chars)),dtype=np.bool)\n",
        "y = np.zeros((len(sentences),len(chars)),dtype=np.bool)\n",
        "\n",
        "for i,sentence in enumerate(sentences):\n",
        "  for t , char in enumerate(chars):\n",
        "    x[i,t,char_indices[char]] = 1\n",
        "  y[i,char_indices[next_chars[i]]] = 1\n",
        "\n",
        "print(x.shape)\n",
        "print(y.shape)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sequences: 200278\n",
            "Unique charactors: 57\n",
            "Vectorization....\n",
            "(200278, 60, 57)\n",
            "(200278, 57)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y067sLgYEdfj"
      },
      "source": [
        "# DeepDream"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvXyENbyE8Yi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebiXVEodEhGR"
      },
      "source": [
        "# 神經風格轉換"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxPM68CzE9rj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9HFRy4cEkz7"
      },
      "source": [
        "# 使用變分自編碼器 Variational Autoencoders 生成圖像"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KRfIi8rE-Fe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bm6Kv0p9EwN7"
      },
      "source": [
        "# 生成對抗神經網路簡介 Generative Adversarial Network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldasFvZ_E-pk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}